#urls.py

from django.urls import path
from . import views
from PIL import Image
import io


urlpatterns = [
    path('', views.home, name='potato-home'),
    path('about/', views.about, name='potato-about'),
    path('latestnews/', views.latest_news, name='latest-news'),
    # æ˜¾ç¤ºæ‰€æœ‰åœ°ç‚¹çš„ç”Ÿé•¿é˜¶æ®µæ€»è§ˆ
    path('location_growth_stage/', views.location_growth_stage, name='location_growth_stage'),
    path('download_growth_stage/', views.download_location_growth_stage, name='download_location_growth_stage'),  # ä¸‹è½½ Excel
    path('error/', views.about, name='error'),
    path('success/', views.about, name='success'),
    path("upload/", views.pre_page, name="potato-upload"),  # è®¿é—® /pre/ æ˜¾ç¤ºé¢„æµ‹é¡µé¢
    path("predict_images/", views.combined_predict, name="predict_images"),
    path('create-superuser/', views.create_superuser_view, name='create_superuser'),
    path('image-fetch-config/', views.fetch_config_view, name='fetch_config'),  # å¤„ç†é…ç½®é¡µé¢
    path('local_dec/', views.pre_page, name='local_dec'),
]

#moedls.py
# æ ‡å‡†åº“å¯¼å…¥
import logging
import os
import re
# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
from sympy import false
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
from torchvision.models import densenet121, DenseNet121_Weights
import torchvision
# Django å¯¼å…¥
from django.contrib.auth.models import User
from django.core.validators import MaxValueValidator, MinValueValidator
from django.db import models
from django.db.models.signals import post_save, post_delete
from django.dispatch import receiver
from django.utils import timezone
from django.utils.timezone import now
# æœ¬åœ°åº”ç”¨å¯¼å…¥
from .net import AttentionLayer, GlobalNet, Net

STAGE_ORDER = {
    'æ’­ç§æœŸ': 0,
    'å‡ºè‹—æœŸ': 1,
    'åˆ†ææœŸ': 2,
    'èŠ±åºå½¢æˆæœŸ': 3,
    'å¼€èŠ±æœŸ': 4,
    'å¯æ”¶æœŸ': 5
}

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
# è·å– Django åº”ç”¨çš„ç»å¯¹è·¯å¾„
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# è®¾å®šæ¨¡å‹è·¯å¾„
MODEL_PATH = os.path.join(BASE_DIR, "models", "ds.pth")


class GlobalDenseNetModel:
    def __init__(self, model_path):  # å…è®¸ä¼ å…¥æ¨¡å‹è·¯å¾„
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"[DEBUG] å…¨å±€æ¨¡å‹è·¯å¾„: {model_path}")
        print(f"[DEBUG] æ¨¡å‹æ–‡ä»¶å­˜åœ¨: {os.path.exists(model_path)}")


        self.model_path = model_path  # å­˜å‚¨æ¨¡å‹è·¯å¾„
        self.transform = self.get_transform()  # âœ… ç¡®ä¿ get_transform() å­˜åœ¨
        self.model = self.load_model()
        print(f"[DEBUG] æ¨¡å‹åŠ è½½çŠ¶æ€: {self.model is not None}")
        self.class_names = ["æ’­ç§æœŸ","å‡ºè‹—æœŸ", "åˆ†ææœŸ", "èŠ±åºå½¢æˆæœŸ", "å¼€èŠ±æœŸ", "å¯æ”¶æœŸ"]

    def get_transform(self):
        """å®šä¹‰å›¾åƒé¢„å¤„ç†æ­¥éª¤"""
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

    def load_model(self):
        try:
            model = GlobalNet()  # ä½¿ç”¨ä¿®æ­£åçš„æ¨¡å‹ç»“æ„

            # å…¼å®¹æ€§åŠ è½½ï¼ˆå¤„ç†å‚æ•°åä¸åŒ¹é…ï¼‰
            state_dict = torch.load(self.model_path, map_location=self.device)

            # å‚æ•°åæ˜ å°„ä¿®æ­£ï¼ˆæ ¹æ®å®é™…éœ€è¦è°ƒæ•´ï¼‰
            fixed_dict = {}
            for k, v in state_dict.items():
                if k.startswith("densenet."):
                    fixed_k = k.replace("densenet.", "base.")  # ä¿®æ­£å±‚çº§
                    fixed_dict[fixed_k] = v
                else:
                    fixed_dict[k] = v

            model.load_state_dict(fixed_dict, strict=false)  # ä¸¥æ ¼åŒ¹é…
            return model.to(self.device).eval()

        except Exception as e:
            print(f"[ERROR] æ¨¡å‹åŠ è½½å¤±è´¥ç»†èŠ‚: {str(e)}")
            return None

    def predict(self, image):
        """å¯¹ä¸Šä¼ çš„å›¾ç‰‡è¿›è¡Œé¢„æµ‹"""
        if self.model is None:
            return None, None

        try:
            if isinstance(image, str) or hasattr(image, 'read'):
                image = Image.open(image).convert("RGB")
            elif isinstance(image, Image.Image):
                image = image.convert("RGB")
            else:
                raise ValueError("æ— æ•ˆçš„ image ç±»å‹")

            image = self.transform(image).unsqueeze(0).to(self.device)

            with torch.no_grad():
                outputs = self.model(image)
                probabilities = torch.softmax(outputs, dim=1)
                _, predicted = torch.max(outputs, 1)

            pred_class = self.class_names[predicted.item()]
            confidence = probabilities[0][predicted.item()].item()
            return pred_class, confidence

        except Exception as e:
            logging.error(f"é¢„æµ‹å¤±è´¥: {e}")
            return None, None




class DenseNetModel:
    def __init__(self, model_path):  # å…è®¸ä¼ å…¥æ¨¡å‹è·¯å¾„
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model_path = model_path  # å­˜å‚¨æ¨¡å‹è·¯å¾„
        self.transform = self.get_transform()  # âœ… ç¡®ä¿ get_transform() å­˜åœ¨
        self.model = self.load_model()  # åŠ è½½æ¨¡å‹
        self.class_names = ["å‡ºè‹—æœŸ", "åˆ†ææœŸ", "èŠ±åºå½¢æˆæœŸ", "å¼€èŠ±æœŸ", "å¯æ”¶æœŸ"]

    def get_transform(self):
        """å®šä¹‰å›¾åƒé¢„å¤„ç†æ­¥éª¤"""
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

    def load_model(self):
        """åŠ è½½ PyTorch æ¨¡å‹"""
        if not os.path.exists(self.model_path):
            logging.error(f"æ¨¡å‹æ–‡ä»¶ {self.model_path} ä¸å­˜åœ¨")
            return None
        try:
            model = Net().to(self.device)
            model.load_state_dict(torch.load(self.model_path, map_location=self.device))
            model.eval()
            logging.info(f"æˆåŠŸåŠ è½½æ¨¡å‹: {self.model_path}")
            return model
        except Exception as e:
            logging.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return None

    def predict(self, image):
        """å¯¹ä¸Šä¼ çš„å›¾ç‰‡è¿›è¡Œé¢„æµ‹"""
        if self.model is None:
            return None, None

        try:
            image = Image.open(image).convert("RGB")
            image = self.transform(image).unsqueeze(0).to(self.device)

            with torch.no_grad():
                outputs = self.model(image)
                probabilities = torch.softmax(outputs, dim=1)
                _, predicted = torch.max(outputs, 1)

            pred_class = self.class_names[predicted.item()]
            confidence = probabilities[0][predicted.item()].item()
            return pred_class, confidence
        except Exception as e:
            logging.error(f"é¢„æµ‹å¤±è´¥: {e}")
            return None, None


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„densenetç‰ˆæœ¬
        self.base_model = torchvision.models.densenet121(pretrained=False)

        # å…³é”®ä¿®æ”¹ç‚¹ï¼šä¸è®­ç»ƒæ—¶çš„ç‰¹å¾ç»´åº¦å¯¹é½
        num_ftrs = self.base_model.classifier.in_features

        # æ„å»ºä¸è®­ç»ƒå®Œå…¨ä¸€è‡´çš„åˆ†ç±»å™¨ç»“æ„
        self.base_model.classifier = nn.Sequential(
            nn.Linear(num_ftrs, 512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, 6)  # ä¿æŒ6ä¸ªè¾“å‡ºèŠ‚ç‚¹
        )

    def forward(self, x):
        return self.base_model(x)


class City(models.Model):
    """åŸå¸‚"""
    name = models.CharField("åŸå¸‚åç§°", max_length=50, unique=True)

    class Meta:
        verbose_name = "åŸå¸‚"
        verbose_name_plural = "åŸå¸‚"

    def __str__(self):
        return self.name

class County(models.Model):
    """å¿åŒº"""
    name = models.CharField("å¿åŒºåç§°", max_length=50)
    city = models.ForeignKey(City, on_delete=models.CASCADE, related_name="counties")

    class Meta:
        unique_together = ('name', 'city')  # ç¡®ä¿å¿åŒºåç§°åœ¨åŒä¸€ä¸ªå¸‚å†…å”¯ä¸€
        verbose_name = "å¿åŒº"
        verbose_name_plural = "å¿åŒº"

    def __str__(self):
        return self.name  # ä»…æ˜¾ç¤ºå¿åŒºåç§°


class Township(models.Model):
    """ä¹¡é•‡"""
    name = models.CharField("ä¹¡é•‡åç§°", max_length=50)
    county = models.ForeignKey(County, on_delete=models.CASCADE, related_name="townships")

    class Meta:
        unique_together = ('name', 'county')
        verbose_name = "ä¹¡é•‡"
        verbose_name_plural = "ä¹¡é•‡"

    def __str__(self):
        return self.name  # ä»…æ˜¾ç¤ºä¹¡é•‡åç§°


class Location(models.Model):

    id = models.AutoField("åºå·", primary_key=True)  # è‡ªåŠ¨é€’å¢
    station_code = models.CharField("ç«™å·", max_length=20, unique=True)  # å­—æ¯+æ•°å­—
    name = models.CharField("ç«™å", max_length=50, unique=True)  # ç«™ç‚¹åç§°
    city = models.ForeignKey(City, on_delete=models.SET_NULL, null=True, verbose_name="åœ°å¸‚")
    county = models.ForeignKey(County, on_delete=models.SET_NULL, null=True, verbose_name="å¿åŒº")
    township = models.ForeignKey(Township, on_delete=models.SET_NULL, null=True, verbose_name="ä¹¡é•‡")
    longitude = models.CharField("ç»åº¦", max_length=20, help_text="ç¤ºä¾‹ï¼šE106 46 42")
    latitude = models.CharField("çº¬åº¦", max_length=20, help_text="ç¤ºä¾‹ï¼šN37 16 55")

    class Meta:
        verbose_name = "é©¬é“ƒè–¯ç«™"
        verbose_name_plural = "é©¬é“ƒè–¯ç«™"

    def __str__(self):
        return f"{self.station_code} - {self.name}"

    def format_dms(self, value):
        """æ ¼å¼åŒ–ç”¨æˆ·è¾“å…¥çš„ç»çº¬åº¦"""
        pattern = r"^([NSEW])\s*(\d+)\s+(\d+)\s+(\d+)$"
        match = re.match(pattern, value.strip())
        if match:
            direction, degrees, minutes, seconds = match.groups()
            return f"{direction} {degrees}Â°{minutes}'{seconds}\""
        return value

    def to_decimal(self, dms_str):
        """å°†åº¦åˆ†ç§’ (DMS) è½¬æ¢ä¸ºåè¿›åˆ¶åº¦ (DD)"""
        pattern = r"([NSEW])\s*(\d+)Â°(\d+)'(\d+)\""
        match = re.match(pattern, dms_str.strip())
        if match:
            direction, degrees, minutes, seconds = match.groups()
            decimal = int(degrees) + int(minutes) / 60 + int(seconds) / 3600
            if direction in ["S", "W"]:  # å—çº¬æˆ–è¥¿ç»ä¸ºè´Ÿæ•°
                decimal = -decimal
            return round(decimal, 6)  # ä¿ç•™ 6 ä½å°æ•°
        return None  # æ— æ³•è½¬æ¢

    def get_decimal_longitude(self):
        return self.to_decimal(self.longitude)

    def get_decimal_latitude(self):
        return self.to_decimal(self.latitude)

    def save(self, *args, **kwargs):
        """åœ¨ä¿å­˜ä¹‹å‰æ ¼å¼åŒ–ç»çº¬åº¦"""
        self.longitude = self.format_dms(self.longitude)
        self.latitude = self.format_dms(self.latitude)
        super().save(*args, **kwargs)


class LocationGrowthStage(models.Model):
    """å­˜å‚¨æ‰€æœ‰é©¬é“ƒè–¯ç”°çš„å®Œæ•´ç”Ÿé•¿é˜¶æ®µå†å²"""

    STAGE_ICONS = {
        'æ’­ç§æœŸ': 'images/æ’­ç§æœŸ.png',
        'å‡ºè‹—æœŸ': 'images/å‡ºè‹—æœŸ.png',
        'åˆ†ææœŸ': 'images/åˆ†ææœŸ.png',
        'èŠ±åºå½¢æˆæœŸ': 'images/èŠ±åºå½¢æˆæœŸ.png',
        'å¼€èŠ±æœŸ': 'images/flowers.png',
        'å¯æ”¶æœŸ': 'images/å¯æ”¶æœŸ.png'
    }

    location = models.ForeignKey(Location, on_delete=models.CASCADE, related_name='growth_stages', verbose_name="ç«™ç‚¹")
    stage = models.CharField("å‘è‚²é˜¶æ®µ", max_length=20)
    stage_start_time = models.DateTimeField("é˜¶æ®µå¼€å§‹æ—¶é—´")
    created_at = models.DateTimeField("è®°å½•æ—¶é—´", auto_now_add=True)

    @property
    def icon(self):
        return self.STAGE_ICONS.get(self.stage, 'images/default.png')

    class Meta:
        ordering = ['-stage_start_time']
        verbose_name = "ç”Ÿé•¿é˜¶æ®µå†å²è®°å½•"
        verbose_name_plural = "ç”Ÿé•¿é˜¶æ®µå†å²è®°å½•"

    def __str__(self):
        return f"{self.location} - {self.stage} - {self.stage_start_time.strftime('%Y-%m-%d %H:%M')}"


class AreaState(models.Model):
    """å­˜å‚¨æ¯ä¸ªåœ°ç‚¹æœ€æ–°çš„ç”Ÿé•¿é˜¶æ®µçŠ¶æ€"""

    location = models.OneToOneField(Location, on_delete=models.CASCADE, primary_key=True, related_name='area_state', verbose_name="ç«™ç‚¹")

    current_stage = models.ForeignKey(LocationGrowthStage, on_delete=models.SET_NULL, null=True,
                                      verbose_name="æœ€æ–°é˜¶æ®µ")

    @property
    def stage(self):
        return self.current_stage.stage if self.current_stage else None

    @property
    def stage_start_time(self):
        return self.current_stage.stage_start_time if self.current_stage else None

    @property
    def longitude(self):
        return self.location.longitude

    @property
    def latitude(self):
        return self.location.latitude

    class Meta:
        verbose_name = "å½“å‰ç”Ÿé•¿çŠ¶æ€"
        verbose_name_plural = "å½“å‰ç”Ÿé•¿çŠ¶æ€"

    def __str__(self):
        return f"{self.location.name} - å½“å‰çŠ¶æ€"


@receiver(post_save, sender=LocationGrowthStage)
def update_area_state(sender, instance, **kwargs):
    """è‡ªåŠ¨æ›´æ–°æœ€æ–°çŠ¶æ€"""
    latest_stage = LocationGrowthStage.objects.filter(
        location=instance.location
    ).order_by('-stage_start_time').first()

    if latest_stage:
        AreaState.objects.update_or_create(location=instance.location, defaults={'current_stage': latest_stage})


class RecognitionResult(models.Model):
    image = models.ImageField("å›¾ç‰‡", upload_to='uploads/')
    location = models.ForeignKey(Location, on_delete=models.CASCADE, null=True, blank=True, verbose_name="ç«™ç‚¹")
    stage = models.CharField("è¯†åˆ«é˜¶æ®µ", max_length=100)
    confidence = models.FloatField("ç½®ä¿¡åº¦")
    shoot_time = models.DateTimeField("æ‹æ‘„æ—¶é—´", null=True, blank=True)
    source = models.CharField("æ¥æº", max_length=10, choices=[('user', 'ç”¨æˆ·ä¸Šä¼ '), ('auto', 'è‡ªåŠ¨è·å–')], default='user')

    class Meta:
        verbose_name = "è¯†åˆ«ç»“æœ"
        verbose_name_plural = "è¯†åˆ«ç»“æœ"

    def __str__(self):
        return f"{self.stage} - {self.confidence * 100:.2f}%"

@receiver(post_save, sender=RecognitionResult)
def update_growth_stage_from_auto(sender, instance, **kwargs):
    if instance.source != 'auto' or not instance.location:
        return  # åªå¤„ç†è‡ªåŠ¨è·å–çš„è®°å½•

    location = instance.location
    new_stage = instance.stage
    shoot_time = instance.shoot_time or now()

    latest_growth = LocationGrowthStage.objects.filter(location=location).order_by('-stage_start_time').first()

    if latest_growth:
        current_stage_index = STAGE_ORDER.get(latest_growth.stage, -1)
        new_stage_index = STAGE_ORDER.get(new_stage, -1)

        if new_stage_index <= current_stage_index:
            return  # é˜¶æ®µå›æº¯æˆ–é‡å¤ï¼Œè·³è¿‡

        if new_stage_index - current_stage_index > 1:
            return  # è·¨é˜¶æ®µï¼Œè·³è¿‡
    # æ·»åŠ æ–°é˜¶æ®µ
    LocationGrowthStage.objects.create(
        location=location,
        stage=new_stage,
        stage_start_time=shoot_time
    )

@receiver(post_delete, sender=LocationGrowthStage)
def update_area_state_on_delete(sender, instance, **kwargs):
    """åˆ é™¤é˜¶æ®µåè‡ªåŠ¨æ›´æ–°AreaStateä¸ºæœ€æ–°çš„é˜¶æ®µï¼ˆæˆ–ç½®ç©ºï¼‰"""
    latest_stage = LocationGrowthStage.objects.filter(
        location=instance.location
    ).order_by('-stage_start_time').first()
    if latest_stage:
        AreaState.objects.update_or_create(location=instance.location, defaults={'current_stage': latest_stage})
    else:
        # æ²¡æœ‰ä»»ä½•é˜¶æ®µäº†ï¼Œç½®ç©º
        AreaState.objects.update_or_create(location=instance.location, defaults={'current_stage': None})


class FetchConfig(models.Model):
    fetch_dir = models.CharField("å›¾ç‰‡æ–‡ä»¶å¤¹æˆ–URL", max_length=512)
    fetch_times = models.IntegerField("æ¯æ—¥è·å–æ¬¡æ•°", default=1)
    fetch_timepoints = models.CharField("è·å–æ—¶é—´ç‚¹", max_length=256)  # 08:00,12:00,18:00
    created_at = models.DateTimeField("åˆ›å»ºæ—¶é—´", auto_now_add=True)

    class Meta:
        verbose_name = "è‡ªåŠ¨è·å–é…ç½®"
        verbose_name_plural = "è‡ªåŠ¨è·å–é…ç½®"

    def __str__(self):
        return self.fetch_dir


#admin.py
from django.contrib import admin
from django import forms
from .models import RecognitionResult, LocationGrowthStage, AreaState, Location, City, County, Township, FetchConfig

@admin.register(RecognitionResult)
class RecognitionResultAdmin(admin.ModelAdmin):
    list_display = ('stage', 'confidence', 'source', 'location', 'shoot_time')
    list_filter = ('source', 'stage', 'location')
    search_fields = ('stage', 'location__name')
    readonly_fields = ('image',)  # ä¸Šä¼ åä¸å¯ä¿®æ”¹å›¾ç‰‡

    # è®¾ç½®ä¸­æ–‡æ˜¾ç¤ºåˆ—å¤´ï¼ˆå¯é€‰ï¼‰
    def get_queryset(self, request):
        return super().get_queryset(request)

    def image_display(self, obj):
        return obj.image.url if obj.image else ""

    image_display.short_description = 'å›¾ç‰‡'


admin.site.site_header = 'åœŸè±†å‘è‚²æœŸè¯†åˆ«ç³»ç»Ÿç®¡ç†åå°'
admin.site.site_title = 'åœŸè±†å‘è‚²æœŸè¯†åˆ«ç³»ç»Ÿç®¡ç†åå°'
admin.site.index_title = 'åœŸè±†å‘è‚²æœŸè¯†åˆ«ç³»ç»Ÿç®¡ç†åå°'


@admin.register(City)
class CityAdmin(admin.ModelAdmin):
    search_fields = ['name']  # ç¡®ä¿å¤–é”®æ”¯æŒæœç´¢

@admin.register(County)
class CountyAdmin(admin.ModelAdmin):
    search_fields = ['name', 'city__name']  # å…è®¸æœç´¢å¿åŒºåç§°å’Œæ‰€å±åŸå¸‚

@admin.register(Township)
class TownshipAdmin(admin.ModelAdmin):
    search_fields = ['name', 'county__name', 'county__city__name']  # å…è®¸æœç´¢ä¹¡é•‡ã€å¿åŒºå’ŒåŸå¸‚


class LocationAdminForm(forms.ModelForm):
    """è‡ªå®šä¹‰ Location è¡¨å•ï¼Œæ”¯æŒå¸‚-å¿åŒº-ä¹¡é•‡è”åŠ¨"""

    class Meta:
        model = Location
        fields = '__all__'

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        # è·å–ç”¨æˆ·é€‰æ‹©çš„å¸‚ï¼Œå¹¶åŠ¨æ€ç­›é€‰å¿åŒº
        if self.instance.pk and self.instance.city:
            self.fields['county'].queryset = County.objects.filter(city=self.instance.city).order_by('name')
        else:
            self.fields['county'].queryset = County.objects.none()  # é»˜è®¤ç©º

        # è·å–ç”¨æˆ·é€‰æ‹©çš„å¿åŒºï¼Œå¹¶åŠ¨æ€ç­›é€‰ä¹¡é•‡
        if self.instance.pk and self.instance.county:
            self.fields['township'].queryset = Township.objects.filter(county=self.instance.county).order_by('name')
        else:
            self.fields['township'].queryset = Township.objects.none()  # é»˜è®¤ç©º


class LocationAdmin(admin.ModelAdmin):
    form = LocationAdminForm
    list_display = ('id', 'station_code', 'name', 'city', 'county', 'township', 'longitude', 'latitude')
    search_fields = ('station_code', 'name', 'city__name', 'county__name', 'township__name')
    list_filter = ('city', 'county', 'township')
    autocomplete_fields = ['city', 'county', 'township']  # è®©å¤–é”®å­—æ®µæ”¯æŒæœç´¢

    def get_form(self, request, obj=None, **kwargs):
        form = super().get_form(request, obj, **kwargs)
        form.base_fields['longitude'].help_text = "ç¤ºä¾‹ï¼šE106 46 42ï¼ˆè‡ªåŠ¨æ ¼å¼åŒ–ä¸º E106Â°46'42\"ï¼‰"
        form.base_fields['latitude'].help_text = "ç¤ºä¾‹ï¼šN37 16 55ï¼ˆè‡ªåŠ¨æ ¼å¼åŒ–ä¸º N37Â°16'55\"ï¼‰"
        return form

    def get_queryset(self, request):
        """ä¼˜åŒ–åˆ—è¡¨æŸ¥è¯¢ï¼Œç¡®ä¿å¿åŒºå’Œä¹¡é•‡ä¸ä¼šé‡å¤åŒ…å«ä¸Šçº§ä¿¡æ¯"""
        queryset = super().get_queryset(request).select_related('city', 'county', 'township')
        return queryset


admin.site.register(Location, LocationAdmin)


@admin.register(LocationGrowthStage)
class LocationGrowthStageAdmin(admin.ModelAdmin):
    list_display = ('get_location_name', 'stage', 'stage_start_time')
    list_select_related = ['location']  # é¢„åŠ è½½å¤–é”®
    search_fields = ('location__name', 'stage')
    list_filter = ('stage',)

    def get_location_name(self, obj):
        return obj.location.name
    get_location_name.short_description = 'ç«™å'
    get_location_name.admin_order_field = 'location__name'  # å¢åŠ æ’åºæ”¯æŒ

@admin.register(AreaState)
class AreaStateAdmin(admin.ModelAdmin):
    list_display = ('location', 'get_stage', 'get_start_time')
    readonly_fields = ('location', 'current_stage')

    def get_stage(self, obj):
        return obj.current_stage.stage if obj.current_stage else '-'
    get_stage.short_description = "æœ€æ–°é˜¶æ®µ"

    def get_start_time(self, obj):
        return obj.current_stage.stage_start_time.strftime('%Y-%m-%d %H:%M') if obj.current_stage else '-'
    get_start_time.short_description = "é˜¶æ®µå¼€å§‹æ—¶é—´"

@admin.register(FetchConfig)
class FetchConfigAdmin(admin.ModelAdmin):
    list_display = ('fetch_dir', 'fetch_times', 'fetch_timepoints', 'created_at')



#views.py

# æ ‡å‡†åº“å¯¼å…¥
import csv
import datetime
import io
import json
import logging
import os
import sys
import time
import traceback
from collections import Counter, defaultdict
# ç¬¬ä¸‰æ–¹åº“å¯¼å…¥
import cv2
import numpy as np
import torch
import torchvision
import torchvision.transforms as T
from PIL import Image, ImageDraw, ImageFont
from pyecharts import options as opts
from pyecharts.charts import Map
from pyecharts.globals import ChartType, SymbolType
from ultralytics import YOLO  # âœ… Ultralytics YOLOv8
# Django æ ‡å‡†åº“å¯¼å…¥
from django.conf import settings
from django.contrib import messages
from django.contrib.auth import login
from django.contrib.auth.models import User
from django.core.files.storage import FileSystemStorage
from django.core.paginator import EmptyPage, PageNotAnInteger, Paginator
from django.core.serializers.json import DjangoJSONEncoder
from django.http import HttpResponse, HttpResponseServerError, JsonResponse
from django.shortcuts import get_object_or_404, redirect, render
from django.utils import timezone
from django.views.decorators.csrf import csrf_exempt
# æœ¬åœ°åº”ç”¨å¯¼å…¥
from .forms import FetchConfigForm, SuperuserCreationForm

from .models import (
    AreaState,
    DenseNetModel,
    GlobalDenseNetModel,
    Location,
    LocationGrowthStage,
    RecognitionResult,
    FetchConfig,
)
from .net import Net

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

def fetch_config_view(request):
    if request.method == 'POST':
        form = FetchConfigForm(request.POST)
        if form.is_valid():
            FetchConfig.objects.all().delete()
            FetchConfig.objects.create(
                fetch_dir=form.cleaned_data['fetch_dir'],
                fetch_times=form.cleaned_data['fetch_times'],
                fetch_timepoints=form.cleaned_data['fetch_timepoints']
            )
            messages.success(request, "å®šæ—¶é…ç½®å·²ä¿å­˜")
            return redirect('fetch_config')
    else:
        config = FetchConfig.objects.last()
        form = FetchConfigForm(initial={
            'fetch_dir': config.fetch_dir if config else '',
            'fetch_times': config.fetch_times if config else 1,
            'fetch_timepoints': config.fetch_timepoints if config else '',
        })
    return render(request, 'potato/image_fetch_config.html', {'form': form})


def draw_chinese_text(img, text, position, font_size=50):
    # è½¬æ¢OpenCVå›¾åƒåˆ°PILæ ¼å¼
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)

    # åŠ è½½ä¸­æ–‡å­—ä½“ï¼ˆéœ€è¦ç¡®ä¿å­—ä½“æ–‡ä»¶å­˜åœ¨ï¼‰
    font_path = "C:/Windows/Fonts/simhei.ttf"  # Windowsç³»ç»Ÿå­—ä½“è·¯å¾„
    font = ImageFont.truetype(font_path, font_size)

    # ç»˜åˆ¶æ–‡æœ¬
    draw.text(position, text, font=font, fill=(0, 255, 0))

    # è½¬æ¢å›OpenCVæ ¼å¼
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)



# è·å–å½“å‰ Django åº”ç”¨çš„ç›®å½•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# åˆå§‹åŒ–æ¨¡å‹
YOLO_MODEL_PATH = os.path.join(BASE_DIR, "models", "best.pt")
yolo_model = YOLO(YOLO_MODEL_PATH)
GLOBAL_MODEL_PATH = os.path.join(BASE_DIR, "models", "best_model_epoch1_acc89.51.pth")
GLOBAL_MODEL = GlobalDenseNetModel(GLOBAL_MODEL_PATH)


class DenseNetModel:
    def __init__(self, model_path):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.class_names = ["å‡ºè‹—æœŸ", "åˆ†ææœŸ", "èŠ±åºå½¢æˆæœŸ", "å¼€èŠ±æœŸ", "å¯æ”¶æœŸ"]
        self.transform = self._get_transform()  # å…ˆåˆå§‹åŒ–transform
        self.model = self._load_model(model_path)  # ååŠ è½½æ¨¡å‹

    def _get_transform(self):
        """ç»Ÿä¸€çš„å›¾åƒé¢„å¤„ç†æµç¨‹"""
        return torchvision.transforms.Compose([
            torchvision.transforms.Resize((224, 224)),
            torchvision.transforms.ToTensor(),
            torchvision.transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])

    def _load_model(self, model_path):
        """å¸¦é”™è¯¯å¤„ç†çš„æ¨¡å‹åŠ è½½"""
        try:
            model = Net()
            state_dict = torch.load(model_path, map_location=self.device)
            # è‡ªåŠ¨è¿‡æ»¤ä¸åŒ¹é…å‚æ•°
            model_dict = model.state_dict()
            matched_dict = {k: v for k, v in state_dict.items() if k in model_dict}
            model_dict.update(matched_dict)

            model.load_state_dict(model_dict)
            return model.eval().to(self.device)
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None

    def predict(self, image):
        """é¢„æµ‹æ–¹æ³•éœ€ä½¿ç”¨transform"""
        if self.model is None:
            return None, None

        try:
            # è½¬æ¢PIL Imageä¸ºTensor
            img_tensor = self.transform(image).unsqueeze(0).to(self.device)
            with torch.no_grad():
                outputs = self.model(img_tensor)
            probabilities = torch.nn.functional.softmax(outputs, dim=1)
            confidence, preds = torch.max(probabilities, 1)
            return self.class_names[preds.item()], confidence.item()
        except Exception as e:
            print(f"é¢„æµ‹é”™è¯¯: {e}")
            return None, None



MODEL_PATH = os.path.join(BASE_DIR, "models", "ds.pth")
DENSENET_MODEL = DenseNetModel(MODEL_PATH)


@csrf_exempt
def combined_predict(request):
    if request.method == "POST" and request.FILES.getlist("images"):
        results = []

        for img_file in request.FILES.getlist("images"):
            fs = FileSystemStorage()
            filename = fs.save(img_file.name, img_file)
            img_path = fs.path(filename)
            img_path_full = os.path.join(settings.MEDIA_ROOT, img_path)

            yolo_results = yolo_model(img_path)
            boxes = yolo_results[0].boxes.xyxy.cpu().numpy()

            stage_conf_list = []  # [(stage, conf)]
            img = Image.open(img_path).convert("RGB")
            img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            overall_stage = "æ— é©¬é“ƒè–¯"
            use_global = False
            confidence = None

            print(f"[DEBUG] YOLOæ£€æµ‹æ¡†æ•°é‡: {len(boxes)}")

            if len(boxes) == 0:
                use_global = True
                stage, confidence = GLOBAL_MODEL.predict(img)
                overall_stage = stage if stage else "æ— é©¬é“ƒè–¯"
            else:
                for box in boxes:
                    x1, y1, x2, y2 = map(int, box)
                    potato_img = img.crop((x1, y1, x2, y2))
                    stage, conf = DENSENET_MODEL.predict(potato_img)
                    if stage:
                        stage_conf_list.append((stage, conf))
                        img_cv = draw_chinese_text(img_cv, stage, (x1 + 5, y1 - 35))
                        cv2.rectangle(img_cv, (x1, y1), (x2, y2), (0, 255, 0), 2)

                total = len(stage_conf_list)
                stages = [s for s, _ in stage_conf_list]

                if total < 5:
                    emergence = stages.count("å‡ºè‹—æœŸ")
                    if total > 0 and emergence / total >= 0.8:
                        overall_stage = "æ’­ç§æœŸ"
                else:
                    for stage in ["å‡ºè‹—æœŸ", "åˆ†ææœŸ", "èŠ±åºå½¢æˆæœŸ", "å¼€èŠ±æœŸ", "å¯æ”¶æœŸ"]:
                        if stages.count(stage) / total >= 0.6:
                            overall_stage = stage
                            break

                # âœ… è®¡ç®—æœ€ç»ˆç½®ä¿¡åº¦
                if overall_stage != "æ— é©¬é“ƒè–¯":
                    matched_conf = [conf for s, conf in stage_conf_list if s == overall_stage]
                    if matched_conf:
                        confidence = (len(matched_conf) / total) * (sum(matched_conf) / len(matched_conf))

            # ä¿å­˜å¤„ç†åå›¾åƒ
            detected_dir = os.path.join("media", "detected")
            os.makedirs(detected_dir, exist_ok=True)
            detected_path = os.path.join(detected_dir, filename)
            cv2.imwrite(detected_path, img_cv)

            # ä¿å­˜åˆ°æ•°æ®åº“
            result = RecognitionResult(
                stage=overall_stage,
                confidence=confidence if confidence is not None else 0.0,
                source="user",
            )
            result.image.save(filename, img_file, save=True)
            result.save()
            if os.path.exists(img_path_full):
                os.remove(img_path_full)
            results.append({
                "original": f"/media/uploads/{filename}",
                "detected": f"/media/detected/{filename}",
                "overall_stage": overall_stage,
                "stages": stages if boxes.any() else [overall_stage],
                "is_global": use_global,
                "confidence": round(confidence, 4) if confidence else None
            })

        return JsonResponse({"results": results})

    return JsonResponse({"error": "æœªä¸Šä¼ å›¾ç‰‡"}, status=400)



def pre_page(request):
    return render(request, 'potato/local_dec.html')

def home(request):
    """è·å–æ‰€æœ‰åœ°ç‚¹çš„æœ€æ–°çŠ¶æ€"""
    current_states = AreaState.objects.select_related('location', 'current_stage').all()

    map_data = []
    for state in current_states:
        growth_stages = state.location.growth_stages.order_by('stage_start_time')

        stage_info = [
            {
                'stage': stage.stage,
                'start_time': stage.stage_start_time.strftime("%Y-%m-%d %H:%M")
            }
            for stage in growth_stages
        ]

        # è½¬æ¢ ç»çº¬åº¦ åˆ°åè¿›åˆ¶ï¼ˆåœ°å›¾éœ€è¦ï¼‰
        decimal_longitude = state.location.get_decimal_longitude()
        decimal_latitude = state.location.get_decimal_latitude()

        map_data.append({
            'name': state.location.name,
            'station_code': state.location.station_code,
            'stages': stage_info,
            'icon': state.current_stage.icon if state.current_stage else 'images/default.png',
            'coord': [decimal_longitude, decimal_latitude]
        })

    context = {
        'area_states': current_states,
        'map_data': map_data
    }
    return render(request, 'potato/home.html', context)


# åˆ›å»ºä¸€ä¸ªæ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)


def about(request):  #åŠ è½½yoloæ¨¡å‹å¹¶æ£€æµ‹ç»“æœ
    return render(request, 'potato/about.html')

def latest_news(request):
    return render(request, 'potato/latest_news.html',{'title':'æœ€æ–°åŠ¨æ€'})

#ç»Ÿè®¡
def location_growth_stage(request):
    """ç»Ÿè®¡é¡µé¢ï¼Œæ”¯æŒå¤šåœ°ç‚¹ã€å¤šçŠ¶æ€ç­›é€‰"""
    # è·å–æ‰€æœ‰å¯ç”¨é€‰é¡¹
    locations = list(Location.objects.values_list('id', 'name').order_by('name'))
    all_location_ids = [loc[0] for loc in locations]
    all_stages = list(LocationGrowthStage.objects.values_list('stage', flat=True).distinct().order_by('stage'))

    # å¤„ç†åœ°ç‚¹å‚æ•°
    location_filter = []
    for loc in request.GET.getlist('location'):
        if loc.strip().isdigit():  # ç¡®ä¿æ˜¯æ•°å­—
            location_id = int(loc)
            if location_id in all_location_ids:
                location_filter.append(location_id)
    if not location_filter:
        location_filter = all_location_ids  # å¦‚æœæ— æ•ˆï¼Œåˆ™æ˜¾ç¤ºå…¨éƒ¨

    # å¤„ç†çŠ¶æ€å‚æ•°
    stage_filter = []
    for stg in request.GET.getlist('stage'):
        if stg in all_stages:  # ç›´æ¥æ£€æŸ¥å­—ç¬¦ä¸²åŒ¹é…
            stage_filter.append(stg)
    if not stage_filter:
        stage_filter = all_stages  # å¦‚æœæ— æ•ˆï¼Œåˆ™æ˜¾ç¤ºå…¨éƒ¨

    # è·å–ç¬¦åˆç­›é€‰æ¡ä»¶çš„æ•°æ®
    location_growth_stages = LocationGrowthStage.objects.all()
    if location_filter != all_location_ids:
        location_growth_stages = location_growth_stages.filter(location__id__in=location_filter)
    if stage_filter != all_stages:
        location_growth_stages = location_growth_stages.filter(stage__in=stage_filter)

    context = {
        'location_growth_stages': location_growth_stages,
        'locations': locations,
        'stages': all_stages,
        'location_filter': location_filter,
        'stage_filter': stage_filter,
    }
    return render(request, 'potato/location_growth_stage.html', context)

#æ–‡ä»¶ä¸‹è½½
def download_location_growth_stage(request):
    """å¯¼å‡º Excelï¼ˆCSVï¼‰ï¼Œæ”¯æŒåœ°ç‚¹å’ŒçŠ¶æ€çš„ç­›é€‰"""

    # **ç¡®ä¿æ­£ç¡®è§£æåœ°ç‚¹å‚æ•°**
    location_filter_str = request.GET.get("location", "").strip()
    location_filter = [int(loc) for loc in location_filter_str.split(",") if
                       loc.isdigit()] if location_filter_str else []

    # **ç¡®ä¿æ­£ç¡®è§£æçŠ¶æ€å‚æ•°**
    stage_filter_str = request.GET.get("stage", "").strip()
    stage_filter = stage_filter_str.split(",") if stage_filter_str else []

    # **åº”ç”¨ç­›é€‰**
    records = LocationGrowthStage.objects.all()
    if location_filter:
        records = records.filter(location__id__in=location_filter)
    if stage_filter:
        records = records.filter(stage__in=stage_filter)

    # **ç”Ÿæˆ CSVï¼ˆExcel å…¼å®¹ï¼‰**
    response = HttpResponse(content_type='text/csv')
    response[
        'Content-Disposition'] = f'attachment; filename="growth_stage_{datetime.datetime.now().strftime("%Y%m%d_%H%M%S")}.csv"'

    response.write('\ufeff')  # è§£å†³ Excel ä¹±ç 
    writer = csv.writer(response)
    writer.writerow(['åœ°ç‚¹', 'çŠ¶æ€', 'æ—¶é—´ç‚¹'])

    for record in records:
        local_time = timezone.localtime(record.stage_start_time)  # ç¡®ä¿æ—¶åŒºæ­£ç¡®
        writer.writerow([
            record.location.name,
            record.stage,
            local_time.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")  # ç¡®ä¿æ ¼å¼ä¸€è‡´
        ])

    return response


def create_superuser_view(request):
    if request.method == 'POST':
        form = SuperuserCreationForm(request.POST)
        if form.is_valid():
            username = form.cleaned_data['username']
            password = form.cleaned_data['password']
            User.objects.create_superuser(username=username, password=password, email=None)
            messages.success(request, f"è¶…çº§ç”¨æˆ· '{username}' åˆ›å»ºæˆåŠŸï¼")
            return redirect('admin:index')  # è·³è½¬åˆ°åå°é¦–é¡µ
    else:
        form = SuperuserCreationForm()
    return render(request, 'potato/create_superuser.html', {'form': form})



#fetch_and_predict.py
import time
import datetime
import logging
import os
import django
from urllib.parse import urlparse
from urllib.request import url2pathname
from io import BytesIO

import numpy as np
import torch
from PIL import Image, ImageOps
import torchvision.transforms as transforms
import cv2
import requests

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'by.settings')
django.setup()
from django.conf import settings
from django.core.files.base import File
from django.utils.timezone import make_aware
from potato.models import RecognitionResult, Location, FetchConfig
from potato.net import GlobalNet, Net

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

YOLO_MODEL_PATH = os.path.join(BASE_DIR, "models", "best.pt")
GLOBAL_MODEL_PATH = os.path.join(BASE_DIR, "models", "best_model_epoch1_acc89.51.pth")
MODEL_PATH = os.path.join(BASE_DIR, "models", "ds.pth")

from ultralytics import YOLO

class GlobalDenseNetModel:
    def __init__(self, model_path):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model_path = model_path
        self.transform = self.get_transform()
        self.model = self.load_model()
        self.class_names = ["æ’­ç§æœŸ", "å‡ºè‹—æœŸ", "åˆ†ææœŸ", "èŠ±åºå½¢æˆæœŸ", "å¼€èŠ±æœŸ", "å¯æ”¶æœŸ"]

    def get_transform(self):
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

    def load_model(self):
        try:
            model = GlobalNet()
            state_dict = torch.load(self.model_path, map_location=self.device)
            fixed_dict = {}
            for k, v in state_dict.items():
                if k.startswith("densenet."):
                    fixed_k = k.replace("densenet.", "base.")
                    fixed_dict[fixed_k] = v
                else:
                    fixed_dict[k] = v
            model.load_state_dict(fixed_dict, strict=False)
            return model.to(self.device).eval()
        except Exception as e:
            print(f"[ERROR] å…¨å±€æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None

    def predict(self, image):
        if self.model is None:
            return None, None
        try:
            if isinstance(image, str) or hasattr(image, 'read'):
                image = Image.open(image).convert("RGB")
            elif isinstance(image, Image.Image):
                image = image.convert("RGB")
            else:
                raise ValueError("æ— æ•ˆçš„ image ç±»å‹")
            image = ImageOps.exif_transpose(image)
            image = self.transform(image).unsqueeze(0).to(self.device)
            with torch.no_grad():
                outputs = self.model(image)
                probabilities = torch.softmax(outputs, dim=1)
                _, predicted = torch.max(outputs, 1)
            pred_class = self.class_names[predicted.item()]
            confidence = probabilities[0][predicted.item()].item()
            return pred_class, confidence
        except Exception as e:
            logging.error(f"å…¨å±€æ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
            return None, None

class DenseNetModel:
    def __init__(self, model_path):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model_path = model_path
        self.transform = self.get_transform()
        self.model = self.load_model()
        self.class_names = ["å‡ºè‹—æœŸ", "åˆ†ææœŸ", "èŠ±åºå½¢æˆæœŸ", "å¼€èŠ±æœŸ", "å¯æ”¶æœŸ"]
    def get_transform(self):
        return transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
    def load_model(self):
        try:
            model = Net()
            state_dict = torch.load(self.model_path, map_location=self.device)
            model.load_state_dict(state_dict)
            return model.eval().to(self.device)
        except Exception as e:
            logging.error(f"DenseNetæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None
    def predict(self, image):
        if self.model is None:
            return None, None
        try:
            if isinstance(image, str) or hasattr(image, 'read'):
                image = Image.open(image).convert("RGB")
            elif isinstance(image, Image.Image):
                image = image.convert("RGB")
            else:
                raise ValueError("æ— æ•ˆçš„ image ç±»å‹")
            image = ImageOps.exif_transpose(image)
            image = self.transform(image).unsqueeze(0).to(self.device)
            with torch.no_grad():
                outputs = self.model(image)
                probabilities = torch.softmax(outputs, dim=1)
                _, predicted = torch.max(outputs, 1)
            idx = predicted.item()
            if idx >= len(self.class_names):
                logging.error(f"DenseNetç±»åˆ«ç´¢å¼•è¶Šç•Œ: {idx} >= {len(self.class_names)}")
                return None, None
            pred_class = self.class_names[idx]
            confidence = probabilities[0][idx].item()
            return pred_class, confidence
        except Exception as e:
            logging.error(f"DenseNetæ¨¡å‹é¢„æµ‹å¤±è´¥: {e}")
            return None, None

def draw_chinese_text(img_cv, text, pos, color=(0,255,0), font_scale=0.7, thickness=2):
    from PIL import ImageFont, ImageDraw
    font_path = os.path.join(BASE_DIR, "simhei.ttf")
    font = ImageFont.truetype(font_path, 22)
    img_pil = Image.fromarray(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    draw.text(pos, text, font=font, fill=color)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

yolo_model = YOLO(YOLO_MODEL_PATH)
GLOBAL_MODEL = GlobalDenseNetModel(GLOBAL_MODEL_PATH)
DENSENET_MODEL = DenseNetModel(MODEL_PATH)

def list_images_in_folder(folder_url):
    if folder_url.startswith("file://"):
        parsed_url = urlparse(folder_url)
        local_path = url2pathname(parsed_url.path)
        if os.name == 'nt' and local_path.startswith('/'):
            local_path = local_path.lstrip('/')
        files = os.listdir(local_path)
        return [
            os.path.join(local_path, f)
            for f in files
            if f.lower().endswith(('.jpg', '.jpeg', '.png'))
        ]
    elif folder_url.startswith("http"):
        list_url = folder_url.rstrip('/') + '/list.json'
        try:
            resp = requests.get(list_url, timeout=10)
            if resp.status_code == 200:
                return resp.json().get('images', [])
        except Exception as e:
            print(f"âŒ è·å–è¿œç¨‹å›¾ç‰‡åˆ—è¡¨å¤±è´¥: {e}")
        return []
    else:
        return []

def fetch_and_predict():
    config = FetchConfig.objects.last()
    if not config:
        print("âŒ æœªé…ç½®å›¾ç‰‡æ–‡ä»¶å¤¹åœ°å€")
        return

    folder_url = config.fetch_dir.strip()
    print(f"ğŸ“¥ å½“å‰å›¾ç‰‡æ–‡ä»¶å¤¹åœ°å€ä¸º: {folder_url}")

    all_images = list_images_in_folder(folder_url)
    if not all_images:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡")
        return

    processed_count = 0
    new_count = 0

    for img_path in all_images:
        filename = os.path.basename(img_path)

        # è§£æç«™ç‚¹å·ä¸æ—¶é—´
        parts = filename.split('_')
        if len(parts) < 3:
            print(f"âŒ æ–‡ä»¶åæ ¼å¼é”™è¯¯ï¼š{filename}")
            continue
        station_code = parts[0]
        timestamp_str = parts[2]
        try:
            shoot_time = datetime.datetime.strptime(timestamp_str, "%Y%m%d%H%M%S")
            shoot_time = make_aware(shoot_time)
        except Exception as e:
            print(f"âŒ æ—¶é—´è§£æå¤±è´¥ï¼š{e}ï¼Œæ–‡ä»¶å: {filename}")
            continue

        try:
            location = Location.objects.get(station_code=station_code)
        except Location.DoesNotExist:
            print(f"âŒ æœªæ‰¾åˆ°ç«™ç‚¹ï¼š{station_code}")
            continue

        exists = RecognitionResult.objects.filter(
            location=location,
            shoot_time=shoot_time,
            source='auto'
        ).exists()
        if exists:
            processed_count += 1
            print(f"â© å·²è¯†åˆ«è¿‡: {filename}, è·³è¿‡")
            continue

        # è¯»å–å›¾ç‰‡
        try:
            if img_path.startswith("http"):
                response = requests.get(img_path, timeout=10)
                response.raise_for_status()
                image_bytes = response.content
                img = Image.open(BytesIO(image_bytes)).convert("RGB")
            else:
                img = Image.open(img_path).convert("RGB")
                with open(img_path, "rb") as f:
                    image_bytes = f.read()
            img = ImageOps.exif_transpose(img)
            img_cv = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
        except Exception as e:
            print(f"âŒ å›¾ç‰‡æ‰“å¼€å¤±è´¥ï¼š{e}ï¼Œæ–‡ä»¶å: {filename}")
            continue

        # YOLOæ¨ç†
        yolo_results = yolo_model(img)
        boxes = yolo_results[0].boxes.xyxy.cpu().numpy() if hasattr(yolo_results[0], 'boxes') else []

        stage_conf_list = []
        stages = []
        overall_stage = "æ— é©¬é“ƒè–¯"
        use_global = False
        confidence = None

        print(f"[DEBUG] YOLOæ£€æµ‹æ¡†æ•°é‡: {len(boxes)}")

        if len(boxes) == 0:
            use_global = True
            stage, confidence = GLOBAL_MODEL.predict(img)
            overall_stage = stage if stage else "æ— é©¬é“ƒè–¯"
            stages = [overall_stage]
        else:
            for box in boxes:
                x1, y1, x2, y2 = map(int, box)
                potato_img = img.crop((x1, y1, x2, y2))
                stage, conf = DENSENET_MODEL.predict(potato_img)
                if stage:
                    stage_conf_list.append((stage, conf))
                    img_cv = draw_chinese_text(img_cv, stage, (x1 + 5, y1 - 35))
                    cv2.rectangle(img_cv, (x1, y1), (x2, y2), (0, 255, 0), 2)

            total = len(stage_conf_list)
            stages = [s for s, _ in stage_conf_list]

            if total < 5:
                emergence = stages.count("å‡ºè‹—æœŸ")
                if total > 0 and emergence / total >= 0.8:
                    overall_stage = "æ’­ç§æœŸ"
            else:
                for stage in ["å‡ºè‹—æœŸ", "åˆ†ææœŸ", "èŠ±åºå½¢æˆæœŸ", "å¼€èŠ±æœŸ", "å¯æ”¶æœŸ"]:
                    if stages.count(stage) / total >= 0.6:
                        overall_stage = stage
                        break

            if overall_stage != "æ— é©¬é“ƒè–¯":
                matched_conf = [conf for s, conf in stage_conf_list if s == overall_stage]
                if matched_conf:
                    confidence = (len(matched_conf) / total) * (sum(matched_conf) / len(matched_conf))

        # ä¿å­˜æ£€æµ‹åå›¾ç‰‡
        detected_dir = os.path.join(settings.MEDIA_ROOT, "detected")
        os.makedirs(detected_dir, exist_ok=True)
        detected_path = os.path.join(detected_dir, filename)
        cv2.imwrite(detected_path, img_cv)

        # ä¿å­˜åˆ°æ•°æ®åº“
        try:
            result = RecognitionResult(
                stage=overall_stage,
                confidence=confidence if confidence is not None else 0.0,
                source="auto",
                location=location,
                shoot_time=shoot_time
            )
            # ä¿å­˜åŸå›¾
            result.image.save(filename, File(BytesIO(image_bytes)), save=True)
            result.save()
            print(f"âœ… æˆåŠŸä¿å­˜è¯†åˆ«ç»“æœï¼š{location.name} - {overall_stage} ({filename})")
            new_count += 1
        except Exception as e:
            print(f"âŒ ä¿å­˜è¯†åˆ«ç»“æœå¤±è´¥ï¼š{e}ï¼Œæ–‡ä»¶å: {filename}")
            continue

    print(f"\nå¤„ç†å®Œæˆï¼Œæœ¬æ¬¡æ–°å¢ {new_count} å¼ ï¼Œå·²å­˜åœ¨ {processed_count} å¼ ï¼Œå…¨éƒ¨å›¾ç‰‡æ•° {len(all_images)}")

def get_today_timepoints(timepoints_str):
    """
    è§£æ '08:00,12:00,18:00' ä¸ºä»Šæ—¥çš„ datetime å¯¹è±¡åˆ—è¡¨
    """
    today = datetime.date.today()
    points = []
    for t in timepoints_str.split(","):
        t = t.strip()
        if not t:
            continue
        hour, minute = map(int, t.split(":"))
        points.append(datetime.datetime.combine(today, datetime.time(hour, minute)))
    return points

def schedule_fetch_by_timepoints():
    print("[å®šæ—¶ä»»åŠ¡] å¯åŠ¨è‡ªåŠ¨å®šæ—¶è°ƒåº¦...")
    last_run_points = set()
    while True:
        config = FetchConfig.objects.last()
        if not config or not config.fetch_timepoints:
            print("[å®šæ—¶ä»»åŠ¡] æœªé…ç½®æ—¶é—´ç‚¹ï¼Œç­‰å¾…60ç§’åé‡è¯•")
            time.sleep(60)
            continue

        now = datetime.datetime.now()
        today_points = get_today_timepoints(config.fetch_timepoints)

        for point in today_points:
            # å…è®¸åœ¨æ—¶é—´ç‚¹Â±60ç§’å†…è§¦å‘ï¼Œé˜²æ­¢å°è¯¯å·®
            if point.date() == now.date() and \
                point not in last_run_points and \
                abs((now - point).total_seconds()) < 60:
                print(f"[å®šæ—¶ä»»åŠ¡] åˆ°è¾¾æ—¶é—´ç‚¹ {point.strftime('%H:%M')}ï¼Œè‡ªåŠ¨æ‰§è¡Œä»»åŠ¡")
                fetch_and_predict()
                last_run_points.add(point)

        # å¦‚æœè·¨å¤©ï¼Œé‡ç½®å·²è¿è¡Œç‚¹
        if any(p.date() < now.date() for p in last_run_points):
            last_run_points.clear()
        time.sleep(20)

if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "once":
        fetch_and_predict()
    else:
        schedule_fetch_by_timepoints()
